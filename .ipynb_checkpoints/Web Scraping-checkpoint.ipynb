{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this tutorial, we would be scraping information of products from an e-commerce website newegg.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n",
    "\n",
    "> In order to import the libraries, an installation of the same is required when doing for first time\n",
    "\n",
    "<pre><code>$ pip install beautifulsoup4\n",
    "$ pip install lxml\n",
    "\n",
    "</code></pre>\n",
    "\n",
    "> Link to beautiful soup documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on a webpage for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.newegg.com/Product/ProductList.aspx?Submit=StoreIM&Depa=1&Category=38\"\n",
    "url = \"https://www.newegg.com/Video-Cards-Video-Devices/Category/ID-38?Tpk=graphics%20cards\"\n",
    "# url = \"https://www.newegg.com/Product/ProductList.aspx?Submit=ENE&DEPA=0&Order=BESTMATCH&Description=mobile&N=-1&isNodeId=1\"\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The headers is required to be sent when making a request to server because most servers can identify and block requests coming from a script, remember to be nice with the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a request to the webpage using its URL and convert response to a Beautiful Soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers)\n",
    "\n",
    "soup = BeautifulSoup(response.content, \"lxml\")\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before going ahead let's see how does response and soup look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Out basic commands, refer to the documentation for more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Tag: <title>Graphics Cards and Video Cards - Newegg.com</title>\n",
      "Tag Name: title\n",
      "Title String: Graphics Cards and Video Cards - Newegg.com\n"
     ]
    }
   ],
   "source": [
    "#Basic Traversal\n",
    "\n",
    "# title of the page\n",
    "print(\"Title Tag:\", soup.title)\n",
    "\n",
    "# get attributes:\n",
    "print(\"Tag Name:\", soup.title.name)\n",
    "\n",
    "# get values:\n",
    "print(\"Title String:\",soup.title.string)\n",
    "\n",
    "# # beginning navigation:\n",
    "# print(soup.title.parent.name)\n",
    "\n",
    "# print(soup.h1)\n",
    "\n",
    "# # getting specific values:\n",
    "# print(soup.p)\n",
    "\n",
    "# all p tags\n",
    "# print(soup.find_all('p'))\n",
    "\n",
    "#iterate using loop\n",
    "# for paragraph in soup.find_all('p'):\n",
    "#     print(str(paragraph.text))\n",
    "\n",
    "# for url in soup.find_all('a'):\n",
    "#     print(url.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hold of a product\n",
    "\n",
    "> we'll first extract information from single product, then run a loop for automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = soup.findAll(\"div\", {\"class\":\"item-container\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Records:\", len(containers))\n",
    "\n",
    "# print(containers[0])\n",
    "# paste to sublime and analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out what aspects of the product are we interested in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# What all information do we need?\n",
    "# Information that repeats everywhere\n",
    "# Brand of the product\n",
    "# Names\n",
    "# Price?\n",
    "# Shipping\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = containers[0]\n",
    "\n",
    "#Brand of the product\n",
    "# print(container.a)\n",
    "# print(container.div)\n",
    "\n",
    "# print(container.div.div.a)\n",
    "\n",
    "# #referencing as array\n",
    "# print(container.div.div.a.img[\"title\"])\n",
    "\n",
    "# print(container.div.a)\n",
    "\n",
    "# print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"item-title\" href=\"https://www.newegg.com/Product/Product.aspx?Item=N82E16814125875&amp;ignorebbr=1\" title=\"View Details\"><i class=\"icon-premier icon-premier-xsm\"></i>GIGABYTE GeForce GTX 1070 8GB WINDFORCE OC, GV-N1070WF2OC-8GD R2</a>]\n"
     ]
    }
   ],
   "source": [
    "#title of the product\n",
    "title_container = container.findAll(\"a\", {\"class\":\"item-title\"})\n",
    "\n",
    "print(title_container)\n",
    "# print(title_container[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "        Free Shipping\r\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#shipping price\n",
    "shipping_container = container.findAll(\"li\", {\"class\":\"price-ship\"})\n",
    "\n",
    "print(shipping_container[0].text)\n",
    "# print(shipping_container[0].text.strip())\n",
    "shipping = shipping_container[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price\n",
    "\n",
    "# print(container.div.findAll(\"div\", {\"class\":\"item-action\"})[0].findAll(\"li\", {\"class\":\"price-current\"})[0].sup.text)\n",
    "price_container_d = container.div.findAll(\"div\", {\"class\":\"item-action\"})[0].findAll(\"li\", {\"class\":\"price-current\"})[0].strong.text\n",
    "price_container_c = container.div.findAll(\"div\", {\"class\":\"item-action\"})[0].findAll(\"li\", {\"class\":\"price-current\"})[0].sup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put all this into a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for container in containers:\n",
    "    brand = container.div.div.a.img[\"title\"]\n",
    "   \n",
    "    title_container = container.findAll(\"a\", {\"class\":\"item-title\"})\n",
    "    product_name = title_container[0].text\n",
    "    \n",
    "    shipping_container = container.findAll(\"li\", {\"class\":\"price-ship\"})\n",
    "    shipping = shipping_container[0].text.strip()\n",
    "    \n",
    "#     print(\"Brand:\" + brand)\n",
    "#     print(\"Product Name:\" + product_name)\n",
    "#     print(\"Shipping:\" + shipping)\n",
    "    \n",
    "#     try:\n",
    "#         price_container_d = container.div.findAll(\"div\", {\"class\":\"item-action\"})[0].findAll(\"li\", {\"class\":\"price-current\"})[0].strong.text\n",
    "#         price_container_c = container.div.findAll(\"div\", {\"class\":\"item-action\"})[0].findAll(\"li\", {\"class\":\"price-current\"})[0].sup.text\n",
    "#         print(\"Price:\"+price_container_d+price_container_c)\n",
    "#     except:\n",
    "#         print(\"Price: None\")\n",
    "    \n",
    "   \n",
    "    \n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv file\n",
    "\n",
    "filename = \"all_products.csv\"\n",
    "\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "headers = \"Brand, Product Name, Shipping\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "for container in containers:\n",
    "    brand = container.div.div.a.img[\"title\"]\n",
    "   \n",
    "    title_container = container.findAll(\"a\", {\"class\":\"item-title\"})\n",
    "    product_name = title_container[0].text\n",
    "    \n",
    "    shipping_container = container.findAll(\"li\", {\"class\":\"price-ship\"})\n",
    "    shipping = shipping_container[0].text.strip()\n",
    "\n",
    "    f.write(brand+\",\"+product_name.replace(\",\", \"|\")+\",\"+shipping+\"\\n\")\n",
    "#     print(\"Brand:\" + brand)\n",
    "#     print(\"Product Name:\" + product_name)\n",
    "#     print(\"Shipping:\" + shipping)\n",
    "#     print()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
